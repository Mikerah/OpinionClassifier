{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of New York Times Opinion and News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from misc import create_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize count and tf-idf vectorizers\n",
    "tf_idf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the data from json file\n",
    "data = create_data()\n",
    "# Extract text from articles\n",
    "articles_text = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get count and tf-idf matrices \n",
    "tf_idf_matrix = tf_idf_vectorizer.fit_transform(articles_text)\n",
    "count_matrix = count_vectorizer.fit_transform(articles_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract features\n",
    "tf_idf_feature_names = tf_idf_vectorizer.get_feature_names()\n",
    "count_feature_names = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of topics\n",
    "n_topics = 3\n",
    "\n",
    "# Number of top words per topic\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, learning_method='online').fit(count_matrix)\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=n_topics, init='nndsvd').fit(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA results:\n",
      "Topic 0:\n",
      "mr trump said clinton campaign republican mrs party president people obama new state election voters political like states presidential vote\n",
      "Topic 1:\n",
      "said mr police government united people state states officials country china year military american president war new officers years news\n",
      "Topic 2:\n",
      "said people like new years year world time city just children work percent ms school health women family life 000\n",
      "\n",
      "NMF results:\n",
      "Topic 0:\n",
      "trump mr clinton mrs campaign republican said party voters republicans donald presidential president hillary election obama convention sanders nominee democratic\n",
      "Topic 1:\n",
      "police said people officers court black city law ms department justice mr year new federal officer like state women school\n",
      "Topic 2:\n",
      "mr said united russia turkey government china military syria european islamic states britain russian state war union american syrian erdogan\n"
     ]
    }
   ],
   "source": [
    "# Function to display the top words for lda and nmf\n",
    "def show_topics(model, feature_names,n_top_words_per_topic):\n",
    "    \"\"\"\n",
    "    Shows the number of of words per topic for each topic\n",
    "    :param model Scikit learn model\n",
    "    :param feature_names vector\n",
    "    :param n_top_words_per_topic int\n",
    "    \"\"\"\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" %(topic_index))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words_per_topic-1:-1]]))\n",
    "        \n",
    "# Run show_topics on lda and nmf\n",
    "print(\"LDA results:\")\n",
    "show_topics(lda,count_feature_names,n_top_words)\n",
    "print()\n",
    "print(\"NMF results:\")\n",
    "show_topics(nmf,tf_idf_feature_names,n_top_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run k-means on both count_matrix and tf_idf_matrix\n",
    "km_count = KMeans(n_clusters=n_topics, init='k-means++', max_iter=100, n_init=1).fit(count_matrix)\n",
    "km_tf_idf = KMeans(n_clusters=n_topics, init='k-means++', max_iter=100, n_init=1).fit(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means fit on a tf_idf matrix with tf_idf features\n",
      "Cluster 0:  said\n",
      " mr\n",
      " police\n",
      " people\n",
      " ms\n",
      " new\n",
      " court\n",
      " state\n",
      " government\n",
      " year\n",
      " city\n",
      " like\n",
      " law\n",
      " years\n",
      " party\n",
      " officers\n",
      " time\n",
      " percent\n",
      " world\n",
      " page\n",
      "\n",
      "Cluster 1:  trump\n",
      " mr\n",
      " clinton\n",
      " mrs\n",
      " campaign\n",
      " said\n",
      " republican\n",
      " party\n",
      " voters\n",
      " president\n",
      " republicans\n",
      " donald\n",
      " presidential\n",
      " sanders\n",
      " hillary\n",
      " obama\n",
      " election\n",
      " convention\n",
      " nominee\n",
      " democratic\n",
      "\n",
      "Cluster 2:  said\n",
      " mr\n",
      " united\n",
      " military\n",
      " turkey\n",
      " syria\n",
      " russia\n",
      " islamic\n",
      " china\n",
      " government\n",
      " states\n",
      " state\n",
      " war\n",
      " american\n",
      " russian\n",
      " saudi\n",
      " iran\n",
      " nations\n",
      " syrian\n",
      " nuclear\n",
      "\n",
      "K-means fit on a tf_idf matrix with count features\n",
      "Cluster 0:  said\n",
      " mr\n",
      " police\n",
      " people\n",
      " ms\n",
      " new\n",
      " court\n",
      " state\n",
      " government\n",
      " year\n",
      " city\n",
      " like\n",
      " law\n",
      " years\n",
      " party\n",
      " officers\n",
      " time\n",
      " percent\n",
      " world\n",
      " page\n",
      "\n",
      "Cluster 1:  trump\n",
      " mr\n",
      " clinton\n",
      " mrs\n",
      " campaign\n",
      " said\n",
      " republican\n",
      " party\n",
      " voters\n",
      " president\n",
      " republicans\n",
      " donald\n",
      " presidential\n",
      " sanders\n",
      " hillary\n",
      " obama\n",
      " election\n",
      " convention\n",
      " nominee\n",
      " democratic\n",
      "\n",
      "Cluster 2:  said\n",
      " mr\n",
      " united\n",
      " military\n",
      " turkey\n",
      " syria\n",
      " russia\n",
      " islamic\n",
      " china\n",
      " government\n",
      " states\n",
      " state\n",
      " war\n",
      " american\n",
      " russian\n",
      " saudi\n",
      " iran\n",
      " nations\n",
      " syrian\n",
      " nuclear\n",
      "\n",
      "K-means fit on a count matrix with tf_idf features\n",
      "Cluster 0:  said\n",
      " mr\n",
      " people\n",
      " state\n",
      " police\n",
      " trump\n",
      " government\n",
      " new\n",
      " ms\n",
      " president\n",
      " united\n",
      " year\n",
      " states\n",
      " like\n",
      " years\n",
      " party\n",
      " country\n",
      " clinton\n",
      " american\n",
      " officials\n",
      "\n",
      "Cluster 1:  mr\n",
      " trump\n",
      " said\n",
      " clinton\n",
      " campaign\n",
      " mrs\n",
      " republican\n",
      " president\n",
      " party\n",
      " new\n",
      " people\n",
      " voters\n",
      " state\n",
      " states\n",
      " presidential\n",
      " obama\n",
      " like\n",
      " republicans\n",
      " election\n",
      " political\n",
      "\n",
      "Cluster 2:  said\n",
      " mr\n",
      " people\n",
      " trump\n",
      " new\n",
      " state\n",
      " like\n",
      " states\n",
      " government\n",
      " world\n",
      " year\n",
      " address\n",
      " email\n",
      " united\n",
      " years\n",
      " enter\n",
      " box\n",
      " time\n",
      " president\n",
      " select\n",
      "\n",
      "K-means fit on a count matrix with count features\n",
      "Cluster 0:  said\n",
      " mr\n",
      " people\n",
      " state\n",
      " police\n",
      " trump\n",
      " government\n",
      " new\n",
      " ms\n",
      " president\n",
      " united\n",
      " year\n",
      " states\n",
      " like\n",
      " years\n",
      " party\n",
      " country\n",
      " clinton\n",
      " american\n",
      " officials\n",
      "\n",
      "Cluster 1:  mr\n",
      " trump\n",
      " said\n",
      " clinton\n",
      " campaign\n",
      " mrs\n",
      " republican\n",
      " president\n",
      " party\n",
      " new\n",
      " people\n",
      " voters\n",
      " state\n",
      " states\n",
      " presidential\n",
      " obama\n",
      " like\n",
      " republicans\n",
      " election\n",
      " political\n",
      "\n",
      "Cluster 2:  said\n",
      " mr\n",
      " people\n",
      " trump\n",
      " new\n",
      " state\n",
      " like\n",
      " states\n",
      " government\n",
      " world\n",
      " year\n",
      " address\n",
      " email\n",
      " united\n",
      " years\n",
      " enter\n",
      " box\n",
      " time\n",
      " president\n",
      " select\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_clusters(model,feature_names, top_words, topics):\n",
    "    \"\"\"\n",
    "    Shows top words per cluster\n",
    "    :param model Scikit learn model\n",
    "    :param feature_names vector\n",
    "    :param top_words int\n",
    "    :param topics int\n",
    "    \"\"\"\n",
    "    order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = feature_names\n",
    "    \n",
    "    for i in range(topics):\n",
    "        print(\"Cluster %d: \" % i, end='')\n",
    "        for ind in order_centroids[i, :top_words]:\n",
    "            print(' %s' % terms[ind])\n",
    "        print()\n",
    "\n",
    "# Run show_clusters on K-means objects and feature_names vectors\n",
    "print(\"K-means fit on a tf_idf matrix with tf_idf features\")\n",
    "show_clusters(km_tf_idf, tf_idf_feature_names,n_top_words,n_topics)\n",
    "print(\"K-means fit on a tf_idf matrix with count features\")\n",
    "show_clusters(km_tf_idf, count_feature_names,n_top_words,n_topics)\n",
    "print(\"K-means fit on a count matrix with tf_idf features\")\n",
    "show_clusters(km_count, tf_idf_feature_names, n_top_words,n_topics)\n",
    "print(\"K-means fit on a count matrix with count features\")\n",
    "show_clusters(km_count, count_feature_names, n_top_words,n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipelines for each classifier \n",
    "pipeline_multinomial_nb_count = Pipeline([('vectorizer', CountVectorizer()),('classifier', MultinomialNB())])\n",
    "pipeline_multinomial_nb_tf_idf = Pipeline([('vectorizer', TfidfVectorizer()), ('classifier', MultinomialNB())])\n",
    "pipeline_logistic_regression_count = Pipeline([('vectorizer', CountVectorizer()),('classifier', LogisticRegression())])\n",
    "pipeline_logistic_regression_tf_idf = Pipeline([('vectorizer', TfidfVectorizer()),('classifier', LogisticRegression())])\n",
    "pipeline_random_forest_count = Pipeline([('vectorizer', CountVectorizer()),('classifier', RandomForestClassifier())])\n",
    "pipeline_random_forest_tf_idf = Pipeline([('vectorizer', TfidfVectorizer()),('classifier', RandomForestClassifier())])\n",
    "pipeline_decision_tree_count = Pipeline([('vectorizer', CountVectorizer()), ('classifier', DecisionTreeClassifier())])\n",
    "pipeline_decision_tree_tf_idf = Pipeline([('vectorizer', CountVectorizer()), ('classifier', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use 10-fold cross validation to determine accuracy of each method\n",
    "k_fold = KFold(n_splits=10)\n",
    "scores_count = {'Multinomial Naive Bayes':[], 'Logistic Regression':[], 'Random Forests': [], 'Decision Trees':[]}\n",
    "scores_tf_idf = {'Multinomial Naive Bayes':[], 'Logistic Regression':[], 'Random Forests': [], 'Decision Trees':[]}\n",
    "\n",
    "def compute_scores(pipeline,type_of_classifier,scores):\n",
    "    \"\"\"\n",
    "    Compute the scores for each classifier given a corresponding pipeline and scores them in a dictionary\n",
    "    :param pipeline sklean Pipeline\n",
    "    :param type_of_classifier str\n",
    "    :param scores dictionary\n",
    "    \"\"\"\n",
    "    for train_indices, test_indices in k_fold.split(data['text']):\n",
    "        train_text = data.iloc[train_indices]['text'].values\n",
    "        train_y = data.iloc[train_indices]['type'].values\n",
    "\n",
    "        test_text = data.iloc[test_indices]['text'].values\n",
    "        test_y = data.iloc[test_indices]['type'].values\n",
    "\n",
    "        pipeline.fit(train_text, train_y)\n",
    "        predictions = pipeline.predict(test_text)\n",
    "\n",
    "        score = f1_score(test_y, predictions,average='weighted')\n",
    "        scores[type_of_classifier].append(score)\n",
    "    scores[type_of_classifier] = sum(scores[type_of_classifier])/len(scores[type_of_classifier])\n",
    "        \n",
    "# Multinomial NB\n",
    "compute_scores(pipeline_multinomial_nb_count, 'Multinomial Naive Bayes', scores_count)\n",
    "compute_scores(pipeline_multinomial_nb_tf_idf, 'Multinomial Naive Bayes', scores_tf_idf)\n",
    "\n",
    "# Logistic Regression\n",
    "compute_scores(pipeline_logistic_regression_count, 'Logistic Regression', scores_count)\n",
    "compute_scores(pipeline_logistic_regression_tf_idf, 'Logistic Regression', scores_tf_idf)\n",
    "\n",
    "# Random Forests\n",
    "compute_scores(pipeline_random_forest_count, 'Random Forests', scores_count)\n",
    "compute_scores(pipeline_random_forest_tf_idf, 'Random Forests', scores_tf_idf)\n",
    "\n",
    "# Decision Trees\n",
    "compute_scores(pipeline_decision_tree_count, 'Decision Trees', scores_count)\n",
    "compute_scores(pipeline_decision_tree_tf_idf, 'Decision Trees', scores_tf_idf)\n",
    "\n",
    "# Display scores\n",
    "print(scores_count)\n",
    "print(scores_tf_idf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
